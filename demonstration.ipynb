{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from LPCA import LogisticPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a toy binary dataset and artificially assign probability to different points. \n",
    "P(0, 1) = 0.4, P(1, 1) = 0.3, P(1, 0) = 0.2, P(0, 0) = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[0, 1],\n",
    "                   [0, 1],\n",
    "                   [0, 1],\n",
    "                   [0, 1],\n",
    "                   [1, 1], \n",
    "                   [1, 1], \n",
    "                   [1, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 0],\n",
    "                   [0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can train a Logistic PCA dimension reducer on this data. We will reduce the data from two dimensions to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Percent of Deviance Explained: 62.359%\n",
      "Log Likelihood: -4.69\n",
      "\n",
      "Iteration: 10\n",
      "Percent of Deviance Explained: 65.125%\n",
      "Log Likelihood: -4.55\n",
      "\n",
      "Reached Convergence on Iteration #15\n",
      "Training Complete. Converged Reached: True\n",
      "Percent of Deviance Explained: 65.127 %\n",
      "Total Training Time: 0.0s\n"
     ]
    }
   ],
   "source": [
    "lpca = LogisticPCA(m=6, k=1, verbose=True, verbose_interval=10)\n",
    "lpca.fit(matrix, maxiters=50, tol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting, we can call transform to reduce a new matrix of observations into the natural parameters on the lower dimensional subspace. Taking the sigmoid of these natural parameters brings the reduced values from the natural parameter space back to our feature space (though still at a lower dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99752738]\n",
      " [0.47009074]\n",
      " [0.00247262]\n",
      " [0.52197183]]\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([[0, 1], \n",
    "                   [1, 1],\n",
    "                   [1, 0],\n",
    "                   [0, 0]])\n",
    "\n",
    "transformed = lpca.transform(test_data)\n",
    "sig = lpca.sigmoid(transformed)\n",
    "print(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reconstruct the original data using the reconstruct method. This will take the reduced natural parameters and convert them into unreduced natural parameters. Again, we will take the sigmoid of the outputs to bring it back to the feature space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00665333 0.99752738]\n",
      " [0.75784669 0.73506489]\n",
      " [0.99752738 0.00790241]\n",
      " [0.72953016 0.76233936]]\n"
     ]
    }
   ],
   "source": [
    "reconstructed = lpca.reconstruct(transformed)\n",
    "sig = lpca.sigmoid(reconstructed)\n",
    "print(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see most observations were reconstructed fairly well, except for (0, 0) which is blatantly incorrect. This is because in our toy example the model has so few degrees of freedom and the input (0, 0) held little weight in model training. In reality, reducing large datasets explains far more deviance and has more degrees of freedom to capture all relationships.\n",
    "\n",
    "If we want to save the model for later use, we can do so using the save_model method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "lpca.show_info\n",
    "lpca.save_model(\"model.h5\")\n",
    "\n",
    "print()  # For newline\n",
    "\n",
    "# Load it again from memory\n",
    "lpca = LogisticPCA()\n",
    "lpca.load_model(\"model.h5\")\n",
    "lpca.show_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
